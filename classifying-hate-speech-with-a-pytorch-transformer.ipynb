{"cells":[{"metadata":{},"cell_type":"markdown","source":"The goal of this kernel is to train a simple transformer from only pytorch to classify hate speech in comments\nto understand how the transformer works, I would recommend this video it walks through the Attention paper and explains it well\n\nhttps://www.youtube.com/watch?v=U0s0f995w14&t=2522s"},{"metadata":{},"cell_type":"markdown","source":"I will be using  torchtext it's really good for preparing the data, it has a good documentation also \nthose are links about an example using torchtext and a tutorial\n\nhttps://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/\n\nhttp://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/"},{"metadata":{},"cell_type":"markdown","source":"as this will be a classification task, we will just need the encoder part of the transformer, so I used the transformer encoder layer from pytorch"},{"metadata":{"id":"cj9NXWy3zd4T","outputId":"0d72ee04-eea7-42f6-e1f0-d7fccc461a9a","trusted":true},"cell_type":"code","source":"import random\n\nSEED = 32\nrandom.seed(SEED)\n\nimport numpy as np \nimport pandas as pd\nimport spacy\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import  f1_score\n\nfrom torch import nn\nimport torch\nfrom torchtext import data\nfrom torch.nn  import functional as F\nimport torch.optim as  optim \nif torch.cuda.is_available():  \n  dev = \"cuda:0\" \n  print(\"gpu up\")\nelse:  \n  dev = \"cpu\"  \ndevice = torch.device(dev)","execution_count":1,"outputs":[{"output_type":"stream","text":"gpu up\n","name":"stdout"}]},{"metadata":{"id":"k5O16FLBzhuC","outputId":"6f53909e-a92b-46c6-ed25-95a67abfc8ca","trusted":true},"cell_type":"code","source":"\"\"\"\n\nthose are the libraries I use for processing text\n\n\"\"\"\n\nimport nltk\nnltk.download(\"punkt\")\n\nimport re\nfrom spacy.tokenizer import Tokenizer\nfrom spacy.lang.en import English\nnlp = English()\n\ntokenizer = Tokenizer(nlp.vocab)\n\nfrom nltk import word_tokenize,sent_tokenize\nfrom nltk.stem  import PorterStemmer\n\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\nnltk.download('stopwords')\nstops = stopwords.words(\"english\")\n\n\ndef removepunc(my_str): # function to remove punctuation\n    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n    no_punct = \"\"\n    for char in my_str:\n        if char not in punctuations:\n            no_punct = no_punct + char\n    return no_punct\n\ndef hasNumbers(inputString):\n    return bool(re.search(r'\\d', inputString))\nsnowstem = SnowballStemmer(\"english\")\nportstem = PorterStemmer()\n","execution_count":2,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"}]},{"metadata":{"id":"elXvdWQyzkDw","trusted":true},"cell_type":"code","source":"traindata = pd.read_csv(\"/kaggle/input/hate-speech-detection/toxic_train.csv\")\ntest = pd.read_csv(\"/kaggle/input/hate-speech-detection/toxic_test.csv\")\ntraindata.drop(\"Unnamed: 0\",axis=1,inplace=True)\ntest.drop(\"Unnamed: 0\",axis=1,inplace=True)","execution_count":3,"outputs":[]},{"metadata":{"id":"lTDXODNhzwwz","trusted":true},"cell_type":"code","source":"\"\"\"\nthis function is the tokenizer we are using, it does basic processing also  like ,\nLowercase the text\nremoving punctuation, stop words and numbers,\nit also removes extra spaces and unwanted characters (I use regex for that)\n\n\nbefore using the tokenizer I was testing it on the train dataframe manually  \n\"\"\"\n\ndef myTokenizer(x):\n return  [snowstem.stem(word.text)for word in \n          tokenizer(removepunc(re.sub(r\"\\s+\\s+\",\" \",re.sub(r\"[^A-Za-z0-9()!?\\'\\`\\\"\\r+\\n+]\",\" \",x.lower()))).strip()) \n          if (word.text not in stops and not hasNumbers(word.text)) ]\n","execution_count":4,"outputs":[]},{"metadata":{"id":"udmV7yOmPNt6","trusted":true},"cell_type":"code","source":"\"\"\"\nhere I'm using the torchtext fields and dataset classes they can ease the work to get\nthe dataset ready for the pytorch model\n\nthe class DataFrameDataset is the easiest way I found to turn a dataframe into a torchtext dataset\n\nthis cell will take sometime to finish\n\"\"\"\n\nTEXT = data.Field(tokenize=myTokenizer,batch_first=True,fix_length=140)\nLABEL = data.LabelField(dtype=torch.float ,batch_first=True)\n\n\nclass DataFrameDataset(data.Dataset):\n\n    def __init__(self, df, text_field, label_field, is_test=False, **kwargs):\n        fields = [('comment_text', text_field), ('toxic', label_field)]\n        examples = []\n        for i, row in df.iterrows():\n            label = row.toxic \n            text = row.comment_text\n            examples.append(data.Example.fromlist([text, label], fields))\n\n        super().__init__(examples, fields, **kwargs)\n  \n\ntorchdataset = DataFrameDataset(traindata, TEXT,LABEL)\ntorchtest = DataFrameDataset(test, TEXT,LABEL)","execution_count":5,"outputs":[]},{"metadata":{"id":"-f1hgGywizQT","trusted":true},"cell_type":"code","source":"train_data, valid_data = torchdataset.split(split_ratio=0.8, random_state = random.seed(SEED))","execution_count":6,"outputs":[]},{"metadata":{"id":"O6PUzivRJvL_","trusted":true},"cell_type":"code","source":"\"\"\"\nthis cell build the vocab which means it get all the used words and if also ignores any word \nthat only appeared less than 3 times\n\"\"\"\nTEXT.build_vocab(train_data,min_freq=3)  \nLABEL.build_vocab(train_data)\n","execution_count":7,"outputs":[]},{"metadata":{"id":"QojEJaoBVTJj","outputId":"528174ce-a162-47bf-edb4-ab3358bf296a","trusted":true},"cell_type":"code","source":"#No. of unique tokens in text\nprint(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n\n#No. of unique tokens in label\nprint(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n\n#Commonly used words\nprint(TEXT.vocab.freqs.most_common(10))  \n","execution_count":8,"outputs":[{"output_type":"stream","text":"Size of TEXT vocabulary: 38591\nSize of LABEL vocabulary: 2\n[('articl', 59408), ('page', 45801), ('wikipedia', 38257), ('edit', 33298), ('talk', 32102), ('use', 28301), ('one', 24706), ('like', 24462), ('pleas', 23766), ('would', 23436)]\n","name":"stdout"}]},{"metadata":{"id":"JVrwFrmTqHzc","trusted":true},"cell_type":"code","source":"#set batch size\nBATCH_SIZE = 128\n\n\"\"\"\nwe are using batches for validation and test set because of memory usage we can't pass the whole set at once \n\"\"\"\n\n\ntrain_iterator,valid_iterator,test_iterator= data.BucketIterator.splits(\n    (train_data,valid_data,torchtest), \n    batch_size = BATCH_SIZE,\n    device = device,\n    sort =False,\nshuffle=False)\n","execution_count":9,"outputs":[]},{"metadata":{"id":"QA57LLmjMCX3","outputId":"964eb82a-0855-4675-a5c7-7ae4f6859d1e","trusted":true},"cell_type":"code","source":"\n\"\"\"\none major point here is that I encoded the embeddings in a different way \nI made an embedding layer for the position then I concatenated position embeddings with the word embeddings \njust thought it could be a usefull way to encode the positions \n\nhad to reshape the output of the transformer layer to get the prediction\n\"\"\"\nclass TextTransformer(nn.Module):\n  def __init__(self):\n    super(TextTransformer,self).__init__()\n    self.wordEmbeddings = nn.Embedding(len(TEXT.vocab),140)\n    self.positionEmbeddings = nn.Embedding(140,20)\n    self.transformerLayer = nn.TransformerEncoderLayer(160,8) \n    self.linear1 = nn.Linear(160,  64)\n    self.linear2 = nn.Linear(64,  1)\n    self.linear3 = nn.Linear(140,  16)\n    self.linear4 = nn.Linear(16,  1)\n  def forward(self,x):\n    positions = (torch.arange(0,140).reshape(1,140) + torch.zeros(x.shape[0],140)).to(device) \n    # broadcasting the tensor of positions \n    sentence = torch.cat((self.wordEmbeddings(x.long()),self.positionEmbeddings(positions.long())),axis=2)\n    attended = self.transformerLayer(sentence)\n    linear1 = F.relu(self.linear1(attended))\n    linear2 = F.relu(self.linear2(linear1))\n    linear2 = linear2.view(-1,140) # reshaping the layer as the transformer outputs a 2d tensor (or 3d considering the batch size)\n    linear3 = F.relu(self.linear3(linear2))\n    out = torch.sigmoid(self.linear4(linear3))\n    return out\n\nmyTransformer = TextTransformer()\nmyTransformer.to(device)\n\n    \n","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"TextTransformer(\n  (wordEmbeddings): Embedding(38591, 140)\n  (positionEmbeddings): Embedding(140, 20)\n  (transformerLayer): TransformerEncoderLayer(\n    (self_attn): MultiheadAttention(\n      (out_proj): Linear(in_features=160, out_features=160, bias=True)\n    )\n    (linear1): Linear(in_features=160, out_features=2048, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear2): Linear(in_features=2048, out_features=160, bias=True)\n    (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n    (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n    (dropout1): Dropout(p=0.1, inplace=False)\n    (dropout2): Dropout(p=0.1, inplace=False)\n  )\n  (linear1): Linear(in_features=160, out_features=64, bias=True)\n  (linear2): Linear(in_features=64, out_features=1, bias=True)\n  (linear3): Linear(in_features=140, out_features=16, bias=True)\n  (linear4): Linear(in_features=16, out_features=1, bias=True)\n)"},"metadata":{}}]},{"metadata":{"id":"OQOBpRBUAyAk","trusted":true},"cell_type":"code","source":"def calculateMetrics(ypred,ytrue):\n  acc  = accuracy_score(ytrue,ypred)\n  f1  = f1_score(ytrue,ypred)\n  f1_average  = f1_score(ytrue,ypred,average=\"macro\")\n  return \" f1 score: \"+str(round(f1,3))+\" f1 average: \"+str(round(f1_average,3))+\" accuracy: \"+str(round(acc,3))\n  ","execution_count":11,"outputs":[]},{"metadata":{"id":"zbLZTzgxJRIA","outputId":"21fbc41e-a284-4267-d3ca-0c10387db2a7","trusted":true},"cell_type":"code","source":"\"\"\"\nusing adagrad because it assign bigger updates to less frequently updated weights \n(like words that are not used many times)\n\n\"\"\"\n\noptimizer = optim.Adagrad(myTransformer.parameters(),lr = 0.001)\n\nfor i in range(20):\n  trainpreds = torch.tensor([])\n  traintrues = torch.tensor([])\n  for  batch in train_iterator:\n    X = batch.comment_text\n    y = batch.toxic\n    myTransformer.zero_grad()\n    pred = myTransformer(X).squeeze()\n    trainpreds = torch.cat((trainpreds,pred.cpu().detach()))\n    traintrues = torch.cat((traintrues,y.cpu().detach()))\n    err = F.binary_cross_entropy(pred,y)\n    err.backward()\n    optimizer.step()\n  err = F.binary_cross_entropy(trainpreds,traintrues)\n  print(\"train BCE loss: \",err.item(),calculateMetrics(torch.round(trainpreds).numpy(),traintrues.numpy()))\n \n\n  valpreds = torch.tensor([])\n  valtrues = torch.tensor([])\n  for batch in valid_iterator:\n    X = batch.comment_text\n    y = batch.toxic\n    valtrues = torch.cat((valtrues,y.cpu().detach()))\n    pred = myTransformer(X).squeeze().cpu().detach()\n    # print(valtrues.shape)\n    valpreds = torch.cat((valpreds,pred))\n  err = F.binary_cross_entropy(valpreds,valtrues)\n  print(\"validation BCE loss: \",err.item(),calculateMetrics(torch.round(valpreds).numpy(),valtrues.numpy()))\n  ","execution_count":12,"outputs":[{"output_type":"stream","text":"train BCE loss:  0.3100277781486511  f1 score: 0.002 f1 average: 0.476 accuracy: 0.903\nvalidation BCE loss:  0.2964196801185608  f1 score: 0.001 f1 average: 0.475 accuracy: 0.905\ntrain BCE loss:  0.27820736169815063  f1 score: 0.007 f1 average: 0.478 accuracy: 0.904\nvalidation BCE loss:  0.25836822390556335  f1 score: 0.018 f1 average: 0.484 accuracy: 0.905\ntrain BCE loss:  0.2364715188741684  f1 score: 0.164 f1 average: 0.559 accuracy: 0.911\nvalidation BCE loss:  0.22028805315494537  f1 score: 0.285 f1 average: 0.621 accuracy: 0.918\ntrain BCE loss:  0.20641660690307617  f1 score: 0.404 f1 average: 0.682 accuracy: 0.924\nvalidation BCE loss:  0.19979296624660492  f1 score: 0.45 f1 average: 0.706 accuracy: 0.928\ntrain BCE loss:  0.18822012841701508  f1 score: 0.501 f1 average: 0.732 accuracy: 0.932\nvalidation BCE loss:  0.18596026301383972  f1 score: 0.52 f1 average: 0.742 accuracy: 0.934\ntrain BCE loss:  0.1749427169561386  f1 score: 0.558 f1 average: 0.762 accuracy: 0.937\nvalidation BCE loss:  0.1745479255914688  f1 score: 0.562 f1 average: 0.764 accuracy: 0.938\ntrain BCE loss:  0.16431690752506256  f1 score: 0.603 f1 average: 0.786 accuracy: 0.942\nvalidation BCE loss:  0.16594341397285461  f1 score: 0.598 f1 average: 0.784 accuracy: 0.942\ntrain BCE loss:  0.15586669743061066  f1 score: 0.64 f1 average: 0.805 accuracy: 0.946\nvalidation BCE loss:  0.1595478057861328  f1 score: 0.626 f1 average: 0.798 accuracy: 0.945\ntrain BCE loss:  0.14949537813663483  f1 score: 0.667 f1 average: 0.82 accuracy: 0.949\nvalidation BCE loss:  0.15477420389652252  f1 score: 0.652 f1 average: 0.812 accuracy: 0.947\ntrain BCE loss:  0.144425168633461  f1 score: 0.685 f1 average: 0.829 accuracy: 0.951\nvalidation BCE loss:  0.15112121403217316  f1 score: 0.664 f1 average: 0.818 accuracy: 0.948\ntrain BCE loss:  0.14052310585975647  f1 score: 0.698 f1 average: 0.836 accuracy: 0.952\nvalidation BCE loss:  0.14837238192558289  f1 score: 0.669 f1 average: 0.821 accuracy: 0.949\ntrain BCE loss:  0.13758186995983124  f1 score: 0.708 f1 average: 0.842 accuracy: 0.953\nvalidation BCE loss:  0.14606145024299622  f1 score: 0.681 f1 average: 0.827 accuracy: 0.95\ntrain BCE loss:  0.13452255725860596  f1 score: 0.717 f1 average: 0.846 accuracy: 0.954\nvalidation BCE loss:  0.14416690170764923  f1 score: 0.686 f1 average: 0.83 accuracy: 0.951\ntrain BCE loss:  0.13247431814670563  f1 score: 0.724 f1 average: 0.85 accuracy: 0.955\nvalidation BCE loss:  0.14316590130329132  f1 score: 0.692 f1 average: 0.833 accuracy: 0.951\ntrain BCE loss:  0.13019157946109772  f1 score: 0.728 f1 average: 0.852 accuracy: 0.956\nvalidation BCE loss:  0.1416696310043335  f1 score: 0.697 f1 average: 0.835 accuracy: 0.952\ntrain BCE loss:  0.12847259640693665  f1 score: 0.732 f1 average: 0.854 accuracy: 0.956\nvalidation BCE loss:  0.14120671153068542  f1 score: 0.693 f1 average: 0.833 accuracy: 0.951\ntrain BCE loss:  0.1265459656715393  f1 score: 0.737 f1 average: 0.857 accuracy: 0.957\nvalidation BCE loss:  0.13982662558555603  f1 score: 0.699 f1 average: 0.836 accuracy: 0.951\ntrain BCE loss:  0.1254383623600006  f1 score: 0.741 f1 average: 0.859 accuracy: 0.957\nvalidation BCE loss:  0.13933224976062775  f1 score: 0.704 f1 average: 0.839 accuracy: 0.953\ntrain BCE loss:  0.12397575378417969  f1 score: 0.744 f1 average: 0.86 accuracy: 0.958\nvalidation BCE loss:  0.13771289587020874  f1 score: 0.708 f1 average: 0.841 accuracy: 0.953\ntrain BCE loss:  0.12282437086105347  f1 score: 0.747 f1 average: 0.862 accuracy: 0.958\nvalidation BCE loss:  0.13712391257286072  f1 score: 0.706 f1 average: 0.84 accuracy: 0.952\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"so the final scores on validation are  \n\nvalidation BCE loss:  0.137 f1 score: 0.706 f1 average: 0.84 accuracy: 0.952"},{"metadata":{"id":"vordglMh4GGC","outputId":"b65b56fa-c86c-449d-8c97-83e479f537fa","trusted":true},"cell_type":"code","source":"\"\"\"\nnow getting the results on the test set\n\"\"\"\n\ntestpreds = torch.tensor([])\ntesttrues = torch.tensor([])\nfor batch in test_iterator:\n    X = batch.comment_text\n    y = batch.toxic\n    testtrues = torch.cat((testtrues,y.cpu().detach()))\n    pred = myTransformer(X).squeeze().cpu().detach()\n    # print(valtrues.shape)\n    testpreds = torch.cat((testpreds,pred))\nerr = F.binary_cross_entropy(testpreds,testtrues)\nprint(\"test BCE loss: \",err.item(),calculateMetrics(torch.round(testpreds).numpy(),testtrues.numpy()))\n  ","execution_count":15,"outputs":[{"output_type":"stream","text":"test BCE loss:  0.18907569348812103  f1 score: 0.646 f1 average: 0.804 accuracy: 0.932\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"predicted\"] = torch.round(testpreds).numpy()\n\n\n\"\"\"\nthis shows that the model understands the language well \n\n\"\"\"\n\ntest[test.predicted==1].iloc[32:37]\n","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"                                          comment_text  toxic  predicted\n342  you fucking braindead oroszka 50% of the syria...      1        1.0\n357  \" \\r\\n :::::\"\"This I hate Eagles 247 for. sinc...      1        1.0\n370  cause she's just a devil with evil on her mind...      1        1.0\n375  \" \\r\\n ::Can you cite any policies?  If not, w...      1        1.0\n392  Agreed, it is stupid to say that any Malfoy is...      0        1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>342</th>\n      <td>you fucking braindead oroszka 50% of the syria...</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>\" \\r\\n :::::\"\"This I hate Eagles 247 for. sinc...</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>370</th>\n      <td>cause she's just a devil with evil on her mind...</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>\" \\r\\n ::Can you cite any policies?  If not, w...</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>Agreed, it is stupid to say that any Malfoy is...</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}